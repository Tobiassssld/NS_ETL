# NL-RailTraffic-ETL-Pipeline

> Real-time data pipeline for Dutch Railways disruption analysis
> Built with Python, SQL, and Azure-ready architecture

## ğŸ¯ Project Goals
Demonstrate production-grade data engineering practices:
- API integration with error handling
- SQL-based transformations (CTEs, window functions)
- Automated daily execution (GitHub Actions)
- Docker containerization

## ğŸ› ï¸ Tech Stack
- **Python 3.11**: `requests`, `pandas`, `sqlalchemy`
- **Database**: SQLite (local) â†’ Azure SQL (production)
- **Orchestration**: GitHub Actions
- **Deployment**: Docker + Docker Compose

## ğŸ“ˆ Key Features
1. **Incremental Loading**: Only fetch new disruptions (avoids duplicates)
2. **Data Quality**: Great Expectations framework validates schema
3. **Analytics**: Pre-calculated daily KPIs (7-day rolling averages)
4. **Monitoring**: Structured logging to track pipeline health

## ğŸš€ Quick Start
```bash
# Setup
git clone https://github.com/yourname/nl-railtraffic-etl-pipeline
cd nl-railtraffic-etl-pipeline
pip install -r requirements.txt

# Configure
cp .env.example .env
# Add your NS_API_KEY to .env

# Run pipeline
python src/pipeline.py

# View results
sqlite3 data/nl_rail.db "SELECT * FROM daily_stats LIMIT 5;"
```

## ğŸ“Š Sample Analytics Query
See `src/transformation/aggregators.py` for complex SQL with:
- Common Table Expressions (CTEs)
- Window functions (`PERCENT_RANK`, rolling sums)
- Correlated subqueries

## ğŸ³ Docker Deployment
```bash
docker-compose up
```

## â˜ï¸ Azure Migration Path
- [ ] Move raw data to Azure Blob Storage
- [ ] Replace SQLite with Azure SQL Database
- [ ] Deploy via Azure Data Factory

## ğŸ“ Lessons Learned
- **Error Handling**: NS API occasionally times out â†’ implemented retry logic
- **Data Quality**: 3% of records have invalid timestamps â†’ added validators
- **Performance**: Batch inserts 10x faster than row-by-row